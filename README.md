# Data transfer station for image AI in the hospital

A self-hosted digital platform for the secure image exchange and processing integrated with hospital systems using industry standards.

### Technical details

A DICOM aware platform that allows for in-house image processing using AI. Receives medical images from PACS and can trigger AI processing pipelines including routing of incoming and outgoing images on the network. 

With Data Transfer Station you participate in the hospital network as a
fully automated medical service. Radiologists will be sending an exam from PACS, processing
is triggered to generate a report and that report bounces back to the sending system.

The setup describes the roll-out in a docker/docker-compose environment.

## Setup

Make sure that the host system supports docker, cron, python3-sqlalchemy, pyodbc, wget, jq, and dcmtk. We will assume that you start this process as the root user in /root/.

Clone this repository.

```{bash}
cd /root/
git clone https://github.com/HaukeBartsch/data-transfer-station.git
cd data-transfer-station
```

Adjust the configuration files in ./configuration/. Important settings are in select_statements.json, which contains the name of A.I. docker container (AIcore/docker_image) and config.json which contains the name of the incoming AETitle for the processing stream (Streams/trigger/AETitleCalled (AICORE1)), the information for the external logging server (logging) and the destination for generated DICOM files (Streams[0]/destination[0]).


Add the A.I. docker container to the host system.

```{bash}
docker load < segm_ec_vibe.tar
```

Check that a new docker container exists with the name and tag "segm_ec_vibe:latest". This name is referenced in ./configuration/select_statement.json.

### Start the setup

We use docker-compose to setup receiver and trigger services. In order to ensure that all directories exist before this is done a './start.sh' script is provided that first creates the folders in /data and afterwards does a 'docker compose up'. To create the folders and copy files into them the script will ask for sudo permissions.

```bash
./start.sh
```


### Test the receiver

If the setup worked the receiver should be accessible on port 11112 (DICOM). You can send a test dataset to this port and check for success

```{bash}
# apt install dcmtk
storescu -v -aet FIONA -aec AICORE1 -nh +sd +r localhost 11112 <test-data-folder>
```

If the above was successful you should see the data appearing in the archive and raw folders. The location of all the logging files is in /data/logs/*.log. Specifically the following log files contain information on:

 - [/data/logs/trigger.log] Messages generated if new data arrived and is checked for the correct processing stream.
 - [/data/logs/runOneJob.log] Messages generated by the runner on the host system when it tries to execute the A.I. core.
 - [/data/logs/backend-logging.log] Messages that should also appear in the external message database.

## Components

DTS is setup using docker compose. The processing is triggered automatically and generated report documents and structured data are forwarded to another connected systems.

### Receiver

Interfaces with a Picture Archive and Communication System (PACS). Listens for DICOM requests on a port and stores the images to temporarily.

### Trigger

For every incoming dataset a ruleset will qualify a processing stream and write a processing request for the Runner.

### Runner

Executes processing requests in order. Runs directly on the system and starts the docker container performing the data processing. 

### Tracking website

Used to debug processing steps, shows incoming data, error messages and processing logs. Used as well for the configuration of the system.
